# -*- coding: utf-8 -*-
"""Predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RFmeuv2lbpD1TE5YLQwAao1oOSa6-tyw
"""

import pandas as pd
import os
import argparse
import sys
from joblib import load

def label_and_filter_patients(df):
    # Counter to track consecutive 1 values
    counter = 0

    # Iterate over the 'SepsisLabel' column
    if (df['SepsisLabel'] == 1).any():
        new_labels =1
    else:
        new_labels =0

    # Add the new 'Label' column to the dataframe
    df['Label'] = new_labels

    # Find the index of the first occurrence of SepsisLabel = 1, or the last index if not found
    first_sepsis_index = df[df['SepsisLabel'] == 1].index.min()
    if pd.isna(first_sepsis_index):
        first_sepsis_index = df.index.max()

    # Extract the rows until the first sepsis index
    filtered_df = df.loc[:first_sepsis_index, :]

    # Reset the index of the filtered dataframe
    filtered_df.reset_index(drop=True, inplace=True)

    return filtered_df


import pandas as pd

def remove_sepsis_label(df):
    new_df = df.drop('SepsisLabel', axis=1)
    return new_df

def describe_summary(df):
    summary = {}
    num_rows = df.shape[0]
    
    for column in df.columns:
        prefix = column.lower()
        stats = df[column].describe().to_dict()
        #print(stats)
        
        if column.lower() == 'label':
            summary[f"{prefix}_value"] = df['Label'][0]
        else:
            if  stats['count']==1:
              stats['std']= stats['mean']

            if 'count' in stats:
              count = stats['count']
              count_ratio = count / num_rows
              stats['count'] = count_ratio

            mean_key = f"{prefix}_mean"
            std_key = f"{prefix}_std"
            count_key = f"{prefix}_count"
            min_key = f"{prefix}_min"
            max_key = f"{prefix}_max"

            stats[mean_key] = stats.pop('mean')
            stats[std_key] = stats.pop('std')
            stats[count_key] = stats.pop('count')
            stats[min_key] = stats.pop('min')
            stats[max_key] = stats.pop('max')

            
        
            summary.update({k: v for k, v in stats.items() if k in [mean_key, std_key, count_key,min_key,max_key]})
    
    df_summary = pd.DataFrame([summary])
    
    return df_summary
def combine_dataframes(train_path,file_paths):
    combined_df = pd.DataFrame()
    count = 0
    for filename in file_paths:
        
        file_path = os.path.join(train_path, filename)
        df = pd.read_csv(file_path, sep='|')
        #df = select_columns(df)
        # Apply label and filter patients
        df = label_and_filter_patients(df)

        # Remove 'SepsisLabel' column
        df = remove_sepsis_label(df)

        df = describe_summary(df)
        #print(df)
        # Concatenate with combined DataFrame
        combined_df = pd.concat([combined_df, df], ignore_index=True)
        #print(combined_df)


        #print(combined_df)
        count+=1
        if count % 500 == 0:
            print(f"Count: {count}")
    return combined_df

def preprocess(df,imputer):
  """  first_file = "patient_0.psv"

    # Extract the numeric part of the first file name
    first_number = int(''.join(filter(str.isdigit, first_file)))

    file_list = [file for file in os.listdir(path) if file.endswith('.psv')]
    # Sort the file list based on the numeric part of the file names

    sorted_file_list = sorted(file_list, key=lambda x: int(''.join(filter(str.isdigit, x))))

    df = combine_dataframes(path,sorted_file_list)


    df.to_csv('combined_data_{'+path+'}.csv', index=True)"""

  columns_to_drop = ['age_min','age_std','age_count','age_max',
                   'gender_max','gender_min','gender_std', 'gender_count',
                   'unit1_min','unit1_std','unit1_count','unit1_max','unit1_mean',
                   'unit2_min','unit2_std','unit2_count','unit2_max','unit2_mean',
                   'hospadmtime_min','hospadmtime_max','hospadmtime_std','hospadmtime_count',
                   'iculos_min','iculos_mean','iculos_std','iculos_count']
  df.drop(columns = columns_to_drop, inplace=True)
  # Create a dictionary to map the old column names to the new column names
  new_column_names = {'age_mean': 'age',
                      'gender_mean': 'gender',
                      'hospadmtime_mean': 'hospadmtime',
                      'iculos_max': 'iculos' 
                      }

  # Rename the columns using the dictionary
  df = df.rename(columns=new_column_names)
  columns_df_selected_first = ['HR', 'O2Sat', 'Temp', 'SBP', 'DBP', 'Resp',
               'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'Creatinine', 'Bilirubin_direct',
              'Glucose', 'Lactate',  'Potassium',
              'Bilirubin_total', 'TroponinI', 'Hgb', 'WBC',
              'Fibrinogen', 'Platelets', 'Age', 'Gender',
               'ICULOS', 'label']
  columns_df_selected_first = [x.lower() for x in columns_df_selected_first]
  colmns_selected =[]

  for column_to_select in columns_df_selected_first:
    for columns in df.columns:
      if column_to_select in columns:
        colmns_selected.append(columns)
  df = df[colmns_selected]



  too_much_nan = ['hco3_mean', 'hco3_std', 'hco3_min', 'hco3_max', 'fio2_mean',
                  'fio2_std', 'fio2_min', 'fio2_max', 'ph_mean', 'ph_std', 
                  'ph_min', 'ph_max', 'alkalinephos_mean', 'alkalinephos_std', 
                  'alkalinephos_min', 'alkalinephos_max', 'paco2_mean', 
                  'paco2_std', 'paco2_min', 'paco2_max', 'sao2_mean', 
                  'sao2_std', 'sao2_min', 'sao2_max', 'bilirubin_direct_mean',
                  'bilirubin_direct_std', 'bilirubin_direct_min', 'bilirubin_direct_max', 
                  'lactate_mean', 'lactate_std', 'lactate_min', 'lactate_max', 
                  'bilirubin_total_mean', 'bilirubin_total_std', 'bilirubin_total_min', 
                  'bilirubin_total_max', 'troponini_mean', 'troponini_std', 
                  'troponini_min', 'troponini_max', 'fibrinogen_mean', 
                  'fibrinogen_std', 'fibrinogen_min', 'fibrinogen_max']
  df.drop(columns = too_much_nan, inplace=True)

  x = df.drop('label_value', axis=1)
  x_colmns = x.columns
  print('Missing: %d' % x.isna().sum().sum())
  y = df['label_value']
  #imputer = KNNImputer()
  #imputer.fit(x)
  new_x = imputer.transform(x)
  new_x_df = pd.DataFrame(new_x, columns = x_colmns)
  print('Missing: %d' % new_x_df.isna().sum().sum())
  return new_x_df, y

# Create an argument parser
parser = argparse.ArgumentParser(description='Script to predict and save results')
parser.add_argument('data_path', type=str, help='Path to the patient data directory')
args = parser.parse_args()


first_file = "patient_0.psv"

# Extract the numeric part of the first file name
first_number = int(''.join(filter(str.isdigit, first_file)))


# Read all the files in the data directory


file_list_test = [file for file in os.listdir(args.data_path) if file.endswith('.psv')]

sorted_file_list_test = sorted(file_list_test, key=lambda x: int(''.join(filter(str.isdigit, x))))
df = combine_dataframes(sys.argv[1],sorted_file_list_test)

# Load the saved KNNImputer model from a file
imputer = load('knn_imputer_model.joblib')

X_test, y_test = preprocess(df,imputer)

loaded_model = load('model_model_GBC.pkl')

# Use the loaded model for predictions
y_pred = loaded_model.predict(X_test)
#save the prediction
# Create a DataFrame with 'id' and 'prediction' columns
data = {'id': ['patient_{}'.format(i) for i in range(len(y_pred))],
        'prediction': y_pred}
df = pd.DataFrame(data)

# Save the DataFrame as a CSV file
df.to_csv('predictions.csv', index=False)